# -*- coding: utf-8 -*-
"""230128.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iu6AATcw7kDr3jILyvD910x2FbutfToK

###2023-01-28 python advanced project camp 4th class

##네이버 영화 랭킹 끌어오기
"""

import requests
from bs4 import BeautifulSoup

# headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36(KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'}
# headers는 코드단에서 요청했을 때 기본적인 요청을 막아두는 사이들이 많다.
# 그래서 브라우저에는 엔터친 것 마냥 효과를 내어주는 것이다.

# 네이버 영화 랭킹 페이지
data1 = requests.get('https://movie.naver.com/movie/sdb/rank/rmovie.naver') # 네이버 영화 랭킹 끌어오기
data2 = requests.get('https://movie.naver.com/movie/sdb/rank/rmovie.naver?sel=pnt&date=20230127') # 네이버

soup = BeautifulSoup(data1.text, 'html.parser')
# 데이터로 요청 후 BeautifulSoup 형태로 속아내는 것이다.
# 크롤링 시 requests로 요청하고 BeatifulSoup(bs4)로 원하는 정보를 속아낸다.

# 태그 안 텍스트를 찍을 때 : 태그.text
# 태그 안 속성을 찍을 때 : 태그['속성']

 # select_one (하나)
title = soup.select_one('#old_content > table > tbody > tr > td.title > div > a')
# 원래는 title = soup.select_one('#old_content > table > tbody > tr.nth-child(2) > td.title > div > a') 
#이 코드인데 부모 자식간의 관계를 나타내는 코드에 에러가 떠서 위의 코드로 수정을 해보니 되었음;;

print(title.text)
print(title['href'])

trs = soup.select('#old_content > table  > tbody > tr')

for tr in trs:
  print(tr)

"""##제목 (title 가져오기)"""

trs = soup.select('#old_content > table > tbody > tr')

# #old_content > table > tbody > tr:nth-child(2) > td.title > div > a
# => 중복 제외 나머지 td.title > div > a로 title 가져오기
for tr in trs:
  a_tag = tr.select_one('td.title > div > a')
  print(a_tag)

trs = soup.select('#old_content > table > tbody > tr')

for tr in trs:
  a_tag = tr.select_one('td.title > div > a')
  if a_tag is not None:
    title = a_tag.text
    print(title)

"""##평점과 제목을 함께 크롤링"""

soup = BeautifulSoup(data2.text, 'html.parser')

trs = soup.select('#old_content > table  > tbody > tr')

for tr in trs:
  a_tag = tr.select_one('td.title > div > a')
  if a_tag is not None: # 공백 제거
    # #old_content > table > tbody > tr:nth-child(2) > td:nth-child(1) > img
    # rank = tr.select_one('td:nth-child(1) > img')['alt']
    rank = tr.select_one('td > img')['alt']
    title = a_tag.text
    # #old_content > table > tbody > tr:nth-child(1) > td.point
    star = tr.select_one('td.point').text
    print(rank,title,star)

"""##BeautifulSoup 모듈

*   HTML 및 XML 문서를 구문 분석하기 위한 python 패키지
*   DOM 추출
*   기본적으로 UTF-8 인코딩 방식이지만 CP949도 지원

###웹 스크래핑과 웹크롤링

*   웹스크래핑 : 웹사이트 상에서 원하는 정보를 추출하는 기술
*   웹 크롤링 : 웹 크롤러(자동화봇)가정해진 규칙에 따라 웹 페이지를 수집해서 각 사이트의 정보를 분류하는 기술

##BeautifulSoup 모듈을 활용한 스크래핑
"""

# pip install requests
# pip install beautifulsoup4

from urllib.request import urlopen
from bs4 import BeautifulSoup as bs

import pandas as pd
import matplotlib.pyplot as plt

"""##1. 웹페이지 가져오기"""

url = 'https://movie.naver.com/movie/point/af/list.naver'
webpage = urlopen(url).read().decode()
webpage

# pip install lxml
# naver = bs(webpage, 'lxml')

naver = bs(webpage, 'html.parser')
type(naver)

"""2. BeautifulSoup 파싱 메소드

1) 태그명
*   .find(태그명) : 조건에 맞는 태그 1개만 찾음
*   .find_all(태그명) : 조건에 맞는 모든 태그 찾음

2) css 선택자
*   .select_one(선택자) : 조건에 맞는 css선택자 1개만 찾음
*   .select(선택자) : 조건에 맞는 css선택자 찾음
"""

trs = naver.select('#old_content > table tr')[1:]
trs[0]

import numpy as np

# 1. 비어 있는 데이터프레임을 만듦
df = pd.DataFrame(columns={'col1', 'col2', 'col3', 'col4', 'col5', 'col6'})

for item in trs:
  # 2. 데이터프레임에 넣을 리스트 생성 (열의 개수만큼 항목을 가지는 리스트)
  lt = []

  # 파싱
  tds = item.find_all('td') # html 기반

  no = tds[0].text
  writer = tds[1].find('a').text
  em = tds[1].find('em').text
  netizen = tds[1].text.split('\n')[5:-2] # 리스트로 나뉘어져 있는 것을
  netizen = ' '.join(netizen).strip() # join으로 합침
  author = tds[2].text

  # 2 .리스트에 추가
  lt.append(no)
  lt.append(writer)
  lt.append(em)
  lt.append(netizen)
  lt.append(author[:-8])
  lt.append(author[-8:])

  # 3. 데이터프레임에 추가
  # 3-1. 인덱스값 생성
  idx = df.index.max()
  if np.isnan(idx) : idx = 0 # 만약 데이터프레임에 값이 없다면 첫번째에 0을 넣어라
  else : idx = idx + 1 # 아니라면 현재 인덱스 + 1을 하여 다음 인덱스로 지정하라

  # 4. 데이터프레임에 추가
  df.loc[idx] = lt # 인덱스에 해당하는 위치에 데이터프레임에 데이터(리스트의 값)를 넣음
  print(lt)
  # print(f'{no}, {writer}, {em}, {netizen}, {author[:-8]}, {author[-8:]}')

df.columns = ['번호', '영화명', '평점', '리뷰', '작성자아이디', '작성일']
df

df.info() # 데이터프레임의 정보.

df['평점'] = df['평점'].astype('int')

dfg = df.groupby('영화명').mean()
dfg

# 한글 폰트 다운
!sudo apt-get install -y fonts-nanum
!sudo fc-cache -fv
!rm ~/.cache/matplotlib -rf

plt.rc('font', family='NanumBarunGothic')
dfg.sort_values('평점').plot(kind='barh')
plt.show()